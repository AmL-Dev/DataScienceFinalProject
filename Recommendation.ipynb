{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Content base recommendation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the cosine similarity between a given user profile and all book profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting Recomendation.py\n"
     ]
    }
   ],
   "source": [
    "%%file Recomendation.py\n",
    "\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRStep\n",
    "import re\n",
    "import json\n",
    "\n",
    "#ID od the user we want recommendation for\n",
    "##########################################\n",
    "recommendation_user_id = \"367007\"\n",
    "##########################################\n",
    "\n",
    "# List of attributes that we take into account \n",
    "string_vector_attributes = ['series', 'author', 'publisher']\n",
    "list_vector_attributes = ['genres', 'awards', 'setting', 'words']\n",
    "int_vector_attributes = {'pages': 3000} #attribute and inverse coefficient factor\n",
    "\n",
    "#Takes an input string and returns whether it's \"empty\"\n",
    "def Check_not_empty_input(input):\n",
    "  # Check if input is not a NaN and not empty\n",
    "  return input == input and input and input != \" \"\n",
    "\n",
    "# 1.\n",
    "# Finds the user we want to give recommendation to\n",
    "# Then computes the norm of the user vector\n",
    "user_profile = {}\n",
    "user_suqared_norm = 0\n",
    "\n",
    "file_name = \"user_profiles.txt\"\n",
    "with open(file_name, 'r', encoding='utf-8') as file:\n",
    "  while (line := file.readline().rstrip()):\n",
    "    user_profile_data = json.loads(line)\n",
    "    user_profile_id = list(user_profile_data.keys())[0]\n",
    "    \n",
    "    if user_profile_id == recommendation_user_id: # Seeked user found\n",
    "      # Store the user profile vetor\n",
    "      user_profile = user_profile_data[user_profile_id]\n",
    "      \n",
    "      # Compute the norm of the user vector\n",
    "      for attribute in string_vector_attributes + list_vector_attributes:\n",
    "        for key, value in user_profile[attribute].items():\n",
    "          if Check_not_empty_input(key) and Check_not_empty_input(value):\n",
    "            user_suqared_norm += value**2\n",
    "      for attribute, inv_coeff in int_vector_attributes.items():\n",
    "          value = 0\n",
    "          # Check if there is a value and this value is not a NaN\n",
    "          if Check_not_empty_input(user_profile[attribute]):\n",
    "            try:\n",
    "              value = (float(user_profile[attribute]) / inv_coeff)\n",
    "              user_suqared_norm += (value**2)\n",
    "            except ValueError:\n",
    "              value = float('nan')\n",
    "          user_profile[attribute] = value\n",
    "      break  \n",
    "      \n",
    "if user_profile == {}:\n",
    "  print(f\"User id {recommendation_user_id} not found. Please try with another user.\")\n",
    "else:\n",
    "\n",
    "  # MapReduce class to compute the cosine similarity between user_profile and all books\n",
    "  class Recomendation(MRJob):    \n",
    "\n",
    "      # Defines the order of mapper and reducer steps\n",
    "      def steps(self):\n",
    "          return [ MRStep(mapper=self.Mapper_compute_norm, reducer=self.Reducer_compute_cosine) ]\n",
    "\n",
    "      # 2. \n",
    "      # Map step: each book vector is read, transformed back into a dictionary and its norm computed \n",
    "      def Mapper_compute_norm(self, _, line):\n",
    "          # Read the input book vector\n",
    "          book = json.loads(line)\n",
    "          book_id = list(book.keys())[0]\n",
    "          book = book[book_id]\n",
    "\n",
    "          # Compute the norm of the book vector\n",
    "          suqared_norm = 0\n",
    "          for attribute in string_vector_attributes:\n",
    "              if Check_not_empty_input(book[attribute]):\n",
    "                  suqared_norm += 1\n",
    "          for attribute in list_vector_attributes:\n",
    "              if Check_not_empty_input(book[attribute]):\n",
    "                for elmt in book[attribute]:\n",
    "                  if Check_not_empty_input(elmt):\n",
    "                    suqared_norm += 1\n",
    "          for attribute, inv_coeff in int_vector_attributes.items():\n",
    "              value = 0\n",
    "              if Check_not_empty_input(book[attribute]):\n",
    "                  try:\n",
    "                      #divide the attribute value by the coeeficient value\n",
    "                      value = (float(book[attribute]) / inv_coeff)\n",
    "                      suqared_norm += value**2\n",
    "                  except ValueError:\n",
    "                      value = float('nan')\n",
    "              book[attribute] = value\n",
    "          yield book_id, (suqared_norm, book)\n",
    "      \n",
    "      # 3.\n",
    "      # Reduce step: compute the cosine similarity between the user profile and every book item profile\n",
    "      # Only recommend unread books\n",
    "      def Reducer_compute_cosine(self, book_id, norm_and_book):\n",
    "          # Read the input book vector\n",
    "          value = list(norm_and_book)[0]\n",
    "          book_suqared_norm = value[0]\n",
    "          book = value[1]\n",
    "          \n",
    "          # Check that the user have not already read that book\n",
    "          if book[\"title\"] not in user_profile[\"title\"]:\n",
    "            \n",
    "            # Compute the dot prodcut between the user vector and every book vector\n",
    "            dot_product = 0\n",
    "            for attribute in string_vector_attributes:\n",
    "              if Check_not_empty_input(book[attribute]) and Check_not_empty_input(user_profile[attribute]):\n",
    "                for key, value in user_profile[attribute].items():\n",
    "                  if key == book[attribute] and Check_not_empty_input(value):\n",
    "                    dot_product += value\n",
    "            for attribute in list_vector_attributes:\n",
    "              if Check_not_empty_input(book[attribute]) and Check_not_empty_input(user_profile[attribute]):\n",
    "                for key, value in user_profile[attribute].items():\n",
    "                  if Check_not_empty_input(key) and Check_not_empty_input(value) and key in book[attribute]:\n",
    "                    dot_product += value\n",
    "            for attribute, inv_coeff in int_vector_attributes.items():\n",
    "              dot_product += (book[attribute] * user_profile[attribute])\n",
    "\n",
    "            # Compute the cosine simpilarity: X.Y/(||X||.||Y||)\n",
    "            cosine_similartity = dot_product / (user_suqared_norm*book_suqared_norm) if user_suqared_norm*book_suqared_norm != 0 else 0\n",
    "            \n",
    "            yield (book_id), (cosine_similartity)\n",
    "\n",
    "  if __name__ == '__main__':\n",
    "      Recomendation.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Executes the code above to compute the cosine similarity between the user profile and every book profile. Stores the result in the user_book_cosine_similairty file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No configs found; falling back on auto-configuration\n",
      "No configs specified for inline runner\n",
      "Creating temp directory C:\\Users\\Amine\\AppData\\Local\\Temp\\Recomendation.Amine.20221130.143720.580395\n",
      "Running step 1 of 1...\n",
      "job output is in C:\\Users\\Amine\\AppData\\Local\\Temp\\Recomendation.Amine.20221130.143720.580395\\output\n",
      "Streaming final output from C:\\Users\\Amine\\AppData\\Local\\Temp\\Recomendation.Amine.20221130.143720.580395\\output...\n",
      "Removing temp directory C:\\Users\\Amine\\AppData\\Local\\Temp\\Recomendation.Amine.20221130.143720.580395...\n"
     ]
    }
   ],
   "source": [
    "! python Recomendation.py item_profiles.txt > user_book_cosine_similairty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Displays top 10 recommendations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>publisher</th>\n",
       "      <th>coverImg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7153</th>\n",
       "      <td>Catching Fire: The Official Illustrated Movie Companion</td>\n",
       "      <td>Kate Egan</td>\n",
       "      <td>Scholastic Inc.</td>\n",
       "      <td><img src=\"https://i.gr-assets.com/images/S/compressed.photo.goodreads.com/books/1378827944l/17623910.jpg\" width=\"160\" ></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3549</th>\n",
       "      <td>Harry Potter and the Order of the Phoenix (Harry Potter, #5, Part 1)</td>\n",
       "      <td>J.K. Rowling</td>\n",
       "      <td>BBC Audiobooks</td>\n",
       "      <td><img src=\"https://i.gr-assets.com/images/S/compressed.photo.goodreads.com/books/1182710609l/1317181._SX318_.jpg\" width=\"160\" ></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3350</th>\n",
       "      <td>The Hunger Games Tribute Guide</td>\n",
       "      <td>Emily Seife (Goodreads Author)</td>\n",
       "      <td>Scholastic Press</td>\n",
       "      <td><img src=\"https://i.gr-assets.com/images/S/compressed.photo.goodreads.com/books/1322760235l/13027304.jpg\" width=\"160\" ></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18874</th>\n",
       "      <td>Labyrinth: A Novel Based on the Jim Henson Film</td>\n",
       "      <td>A.C.H. Smith, Terry Jones</td>\n",
       "      <td>Henry Holt</td>\n",
       "      <td><img src=\"https://i.gr-assets.com/images/S/compressed.photo.goodreads.com/books/1388179347l/55453.jpg\" width=\"160\" ></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22352</th>\n",
       "      <td>Harry Potter: Film Wizardry</td>\n",
       "      <td>Brian Sibley</td>\n",
       "      <td>Harper Design</td>\n",
       "      <td><img src=\"https://i.gr-assets.com/images/S/compressed.photo.goodreads.com/books/1464452934l/7952502._SX318_.jpg\" width=\"160\" ></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17335</th>\n",
       "      <td>The End of Harry Potter?</td>\n",
       "      <td>David Langford</td>\n",
       "      <td>Tor Books</td>\n",
       "      <td><img src=\"https://i.gr-assets.com/images/S/compressed.photo.goodreads.com/books/1312059991l/389547.jpg\" width=\"160\" ></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12419</th>\n",
       "      <td>Night Witches</td>\n",
       "      <td>L.J. Adlington, Lucy Adlington (Goodreads Author)</td>\n",
       "      <td>Hodder Children's Books</td>\n",
       "      <td><img src=\"https://i.gr-assets.com/images/S/compressed.photo.goodreads.com/books/1370858331l/16068797.jpg\" width=\"160\" ></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5380</th>\n",
       "      <td>The Magical Worlds Of Harry Potter: A Treasury Of Myths, Legends And Fascinating Facts</td>\n",
       "      <td>David Colbert (Goodreads Author)</td>\n",
       "      <td>Penguin Books Ltd</td>\n",
       "      <td><img src=\"https://i.gr-assets.com/images/S/compressed.photo.goodreads.com/books/1181390041l/1145438._SX318_.jpg\" width=\"160\" ></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21965</th>\n",
       "      <td>The Invisible Ring</td>\n",
       "      <td>Anne Bishop</td>\n",
       "      <td>Roc</td>\n",
       "      <td><img src=\"https://i.gr-assets.com/images/S/compressed.photo.goodreads.com/books/1331322774l/47954.jpg\" width=\"160\" ></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5454</th>\n",
       "      <td>Out of Sight, Out of Mind</td>\n",
       "      <td>Marilyn Kaye</td>\n",
       "      <td>Kingfisher</td>\n",
       "      <td><img src=\"https://i.gr-assets.com/images/S/compressed.photo.goodreads.com/books/1327254754l/5602828.jpg\" width=\"160\" ></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from IPython.core.display import HTML\n",
    "\n",
    "book_similarity = []\n",
    "\n",
    "# Read the results from the MapReduce step\n",
    "file_name = \"user_book_cosine_similairty\"\n",
    "with open(file_name, 'r', encoding='utf-8') as file:\n",
    "  while (line := file.readline().rstrip()):\n",
    "    line = line.split('\\t')\n",
    "    book_id = int(line[0].replace(\"\\\"\", \"\"))\n",
    "    similarity = float(line[1])\n",
    "    book_similarity.append([book_id, similarity])\n",
    "\n",
    "# Get the corresponding metadata\n",
    "books_metada = pd.read_csv(\"data/books_metadata.csv\")\n",
    "book_similarity_df = pd.DataFrame(book_similarity, columns=[\"book_id\", \"similarity\"])\n",
    "book_similarity_df = book_similarity_df.merge(books_metada, on = \"book_id\")\n",
    "book_similarity_df = book_similarity_df.sort_values(by=\"similarity\", ascending=False)\n",
    "\n",
    "# 4.\n",
    "# Renders the 10 recommendations with a picture of the book cover.\n",
    "top_ten_recommendation = book_similarity_df[[\"title\", \"author\", \"publisher\", \"coverImg\"]].head(10)\n",
    "\n",
    "# Converting links to html tags\n",
    "def path_to_image_html(path):\n",
    "  return '<img src=\"'+ path + '\" width=\"160\" >'\n",
    "\n",
    "# Rendering the images in the dataframe using the HTML method.\n",
    "HTML(top_ten_recommendation.to_html(escape=False,formatters=dict(coverImg=path_to_image_html)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7a7bc949ac09e1311def83ae0b9d9fa997b438448c6e4b9a59dc0c484a51e208"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
